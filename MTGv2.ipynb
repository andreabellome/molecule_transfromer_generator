{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ETsisHIZ9zvH",
        "qnWMJ1xr99Sn",
        "mp0fqJ7y-xQK"
      ],
      "authorship_tag": "ABX9TyOYovWi+HfkD2xEZa/LOpf2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7ih6koQ9aJK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#from rdkit import Chem\n",
        "\n",
        "# Esempio di stringhe SMILES (in un'applicazione reale, useresti un dataset più ampio)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Esempio di stringhe SMILES (in un'applicazione reale, useresti un dataset più ampio)\n",
        "smiles_corpus = [\n",
        "    \"CC(C)CC1=CC=CC=C1\", \"CC(C)C1=CC=C(C=C1)C(O)=O\", \"CC(C)C1=CC=CC=C1O\", \"CCC1=CC=C(C=C1)C=O\",\n",
        "    \"CCOC(=O)C1=CC=CC=C1\", \"CC(C)C1=CC=C(C=C1)O\", \"COC1=CC=C(C=C1)C(O)=O\", \"CCCC1=CC=C(C=C1)O\",\n",
        "    \"CC(C)CC1=CC=CC=C1O\", \"CC(C)COC1=CC=CC=C1\", \"CCC1=CC=CC=C1OC\", \"CCOC1=CC=CC=C1C\",\n",
        "    \"CCCC1=CC=CC=C1C\", \"CC(C)C1=CC=C(C=C1)C=O\", \"COC1=CC=C(C=C1)C=O\", \"CCC1=CC=C(C=C1)C=O\",\n",
        "    \"CC(C)C1=CC=C(C=C1)C(O)=O\", \"CCOC1=CC=CC=C1O\", \"CCCC1=CC=C(C=C1)O\", \"CC(C)C1=CC=CC=C1C\",\n",
        "    \"CCCC1=CC=CC=C1C=O\", \"CCOC1=CC=CC=C1C=O\", \"CC(C)COC1=CC=CC=C1O\", \"COC1=CC=C(C=C1)C(O)=O\",\n",
        "    \"CC(C)C1=CC=CC=C1OC\", \"CCCC1=CC=CC=C1OC\", \"COC1=CC=CC=C1OC\", \"CCC1=CC=C(C=C1)C(O)=O\",\n",
        "    \"CCCC1=CC=CC=C1OC=O\", \"CCOC1=CC=CC=C1OC\", \"CC(C)C1=CC=CC=C1CO\", \"CCCC1=CC=C(C=C1)C=O\",\n",
        "    \"CCOC1=CC=CC=C1CO\", \"COC1=CC=CC=C1CO\", \"CC(C)CC1=CC=C(C=C1)O\", \"CC(C)CC1=CC=CC=C1CO\",\n",
        "    \"CCCC1=CC=CC=C1CO\", \"CCOC1=CC=CC=C1COC\", \"COC1=CC=C(C=C1)CO\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"CC(C)C1=CC=CC=C1COC\", \"CCCC1=CC=C(C=C1)COC\", \"COC1=CC=C(C=C1)COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CC(C)C1=CC=C(C=C1)C=O\", \"CCCC1=CC=CC=C1COC=O\", \"CC(C)CC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1COC=O\",\n",
        "    \"COC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1C(O)=O\", \"CC(C)COC1=CC=CC=C1C(O)=O\",\n",
        "    \"CC(C)C1=CC=C(C=C1)C=O\", \"CCCC1=CC=C(C=C1)COC=O\", \"CCOC1=CC=CC=C1C(O)=O\", \"COC1=CC=C(C=C1)COC=O\",\n",
        "    \"CCCC1=CC=CC=C1C(O)=O\", \"CC(C)C1=CC=CC=C1COC=O\", \"COC1=CC=CC=C1C(O)=O\", \"CCCC1=CC=CC=C1C(O)=O\",\n",
        "    \"CCOC1=CC=CC=C1C=O\", \"CC(C)C1=CC=CC=C1COC\", \"COC1=CC=C(C=C1)COC=O\", \"CCCC1=CC=CC=C1COC=O\",\n",
        "    \"CC(C)C1=CC=C(C=C1)COC=O\", \"CCCC1=CC=CC=C1COC=O\", \"COC1=CC=C(C=C1)COC\", \"CCOC1=CC=CC=C1COC=O\",\n",
        "    \"CC(C)COC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC=O\", \"CC(C)COC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\",\n",
        "    \"CCOC1=CC=CC=C1COC=O\", \"CC(C)C1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC\", \"CC(C)COC1=CC=CC=C1COC\",\n",
        "    \"COC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC=O\", \"COC1=CC=CC=C1COC\",\n",
        "    \"CC(C)COC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1COC=O\",\n",
        "    \"CC(C)COC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"CCOC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC=O\",\n",
        "    \"CCOC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"COC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1COC=O\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC=O\",\n",
        "    \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"COC1=CC=CC=C1COC=O\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\",\n",
        "    \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\",\n",
        "    \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\",\n",
        "    \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\",\n",
        "    \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\",\n",
        "    \"CCCC1=CC=CC=C1COC\", \"COC1=CC=CC=C1COC\", \"CCOC1=CC=CC=C1COC\", \"CCCC1=CC=CC=C1COC\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "1O5GViEL9ezo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizzazione del testo\n",
        "tokenizer = Tokenizer(char_level=True) # ci interessa scendere nel dettaglio delle molecole\n",
        "tokenizer.fit_on_texts(smiles_corpus) # estrae i token dal corpus\n",
        "total_words = len(tokenizer.word_index) + 1 # la lunghezza del vocabolario\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "# Creazione delle sequenze di input\n",
        "input_sequences = [] #lista vuota delle sequenze di input\n",
        "for line in smiles_corpus: #itero sulle line del corpus i.e. sulle SMILE\n",
        "    #print(line)\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    #print(token_list)\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        #print(n_gram_sequence)\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Padding delle sequenze per avere tutte le stesse lunghezze\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Creazione dei dati di input e output\n",
        "X = input_sequences[:, :-1]\n",
        "y = tf.keras.utils.to_categorical(input_sequences[:, -1], num_classes=total_words)\n",
        "\n",
        "print(\"Forma di X:\", X.shape)\n",
        "print(\"Forma di y:\", y.shape)\n",
        "print(\"Numero totale di parole:\", total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYenL9K_9hvw",
        "outputId": "a0f83667-52a5-4d38-9fb3-da9eec8acb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'c': 1, '=': 2, '1': 3, 'o': 4, '(': 5, ')': 6}\n",
            "Forma di X: (2570, 23)\n",
            "Forma di y: (2570, 7)\n",
            "Numero totale di parole: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRANSFORMER"
      ],
      "metadata": {
        "id": "1c2U2K3o9k3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(vocab_size, embed_dim, num_heads, ff_dim, maxlen):\n",
        "    inputs = layers.Input(shape=(maxlen - 1,))\n",
        "\n",
        "    # Strato di embedding\n",
        "    embedding_layer = layers.Embedding(vocab_size, embed_dim, input_length=maxlen - 1)(inputs)\n",
        "\n",
        "    # Blocco Trasformatore\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(embedding_layer, embedding_layer)\n",
        "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output + embedding_layer)\n",
        "\n",
        "    ff_output = layers.Dense(ff_dim, activation=\"relu\")(attention_output)\n",
        "    ff_output = layers.Dense(embed_dim)(ff_output)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(ff_output + attention_output)\n",
        "\n",
        "    # Pooling e classificatore finale\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "x5jvF_c29kB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the TRANSFORMER"
      ],
      "metadata": {
        "id": "bfto4iUz9qVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametri del modello\n",
        "embed_dim = 64  # Dimensione degli embeddings\n",
        "num_heads = 2   # Numero di teste nel Multi-head attention\n",
        "ff_dim = 64     # Dimensione del feed-forward\n",
        "vocab_size = total_words\n",
        "\n",
        "# Creazione del modello\n",
        "generator = create_transformer_model(vocab_size, embed_dim, num_heads, ff_dim, max_sequence_len)\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "SQnE8TRC9p7A",
        "outputId": "6c2cf7e8-b2c5-423c-c394-e82bbdf71fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_28\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_28\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_31            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_20 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m448\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_10   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m33,216\u001b[0m │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "│                           │                        │                │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_20    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m4,160\u001b[0m │ dense_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_21 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_21    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │          \u001b[38;5;34m1,300\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m147\u001b[0m │ dense_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_31            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_10   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,216</span> │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "│                           │                        │                │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_20    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dense_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_21    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,687\u001b[0m (170.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,687</span> (170.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,687\u001b[0m (170.65 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,687</span> (170.65 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.fit(X, y, epochs=20, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f7nGHoJWfvE",
        "outputId": "16e96c30-567b-46fb-d68d-4c92e0d210eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5077 - loss: 1.3780\n",
            "Epoch 2/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5347 - loss: 1.2935\n",
            "Epoch 3/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5205 - loss: 1.2986\n",
            "Epoch 4/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 1.2631\n",
            "Epoch 5/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5385 - loss: 1.2615\n",
            "Epoch 6/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5483 - loss: 1.2103\n",
            "Epoch 7/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5707 - loss: 1.0482\n",
            "Epoch 8/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6144 - loss: 0.9461\n",
            "Epoch 9/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.8497\n",
            "Epoch 10/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6816 - loss: 0.8034\n",
            "Epoch 11/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.7386\n",
            "Epoch 12/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.7193\n",
            "Epoch 13/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7314 - loss: 0.6766\n",
            "Epoch 14/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7207 - loss: 0.7020\n",
            "Epoch 15/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.6542\n",
            "Epoch 16/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.6231\n",
            "Epoch 17/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7474 - loss: 0.6418\n",
            "Epoch 18/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7428 - loss: 0.6381\n",
            "Epoch 19/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.6097\n",
            "Epoch 20/20\n",
            "\u001b[1m1285/1285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.6095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b72fdd70ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DISCRIMINATOR"
      ],
      "metadata": {
        "id": "ETsisHIZ9zvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_discriminator_model(vocab_size, embed_dim, max_sequence_len):\n",
        "#     inputs = layers.Input(shape=(max_sequence_len,))\n",
        "\n",
        "#     # Embedding layer\n",
        "#     x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "\n",
        "#     # Flatten and classify\n",
        "#     x = layers.Flatten()(x)\n",
        "#     x = layers.Dense(128, activation=\"relu\")(x)\n",
        "#     outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "MtYs4Qdd91eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the DISCRIMINATOR"
      ],
      "metadata": {
        "id": "K6WHp_ZM95mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_embed_dim = 128\n",
        "# Create the generator and discriminator models\n",
        "#generator = create_transformer_model(vocab_size, embed_dim, num_heads, ff_dim, max_sequence_len)\n",
        "discriminator = create_discriminator_model(vocab_size, discriminator_embed_dim, max_sequence_len)\n",
        "discriminator.summary()\n",
        "# Compile the discriminator separately\n",
        "discriminator.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEy3veI597YD",
        "outputId": "d09d2f22-71f1-4281-d518-c4a0222b8c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_21 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m393,344\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,344</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GAN"
      ],
      "metadata": {
        "id": "qnWMJ1xr99Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the GAN model\n",
        "\n",
        "# discriminator.trainable = False\n",
        "\n",
        "# gan_input = layers.Input(shape=(max_sequence_len-1,))\n",
        "# generated_smiles = generator(gan_input)\n",
        "\n",
        "# # Define the padding amounts\n",
        "# padding_amount = [[0, 0], [0, max_sequence_len - generated_smiles.shape[1]]]  # Pad the sequences to match max_sequence_len\n",
        "\n",
        "# padded_smiles = layers.Lambda(\n",
        "#     lambda x: tf.pad(x, padding_amount),\n",
        "#     output_shape=(max_sequence_len, generated_smiles.shape[-1])\n",
        "# )(generated_smiles)\n",
        "\n",
        "# print(padded_smiles)\n",
        "\n",
        "# discriminator.trainable = True\n",
        "\n",
        "# gan_output = discriminator(padded_smiles)\n",
        "# gan = tf.keras.Model(gan_input, gan_output)\n",
        "\n",
        "# # gan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "# gan.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy']) # Added accuracy metric\n",
        "\n",
        "# gan.summary()\n"
      ],
      "metadata": {
        "id": "YLsmGRXs9-xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING LOOP"
      ],
      "metadata": {
        "id": "mp0fqJ7y-xQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training parameters\n",
        "# epochs = 10       # Number of training epochs\n",
        "# batch_size = 2      # Batch size\n",
        "# save_interval = 10  # Interval to save generated samples\n",
        "\n",
        "# #  real data (replace with actual SMILES strings data)\n",
        "# real_smile_strings = input_sequences\n",
        "\n",
        "# # Training loop\n",
        "# for epoch in range(epochs):\n",
        "\n",
        "#     # ---------------------\n",
        "#     #  Train Discriminator\n",
        "#     # ---------------------\n",
        "\n",
        "#     # Generate a batch of fake SMILES strings\n",
        "#     noise = np.random.randint(0, vocab_size, (batch_size, max_sequence_len - 1))\n",
        "#     generated_smiles = generator.predict(noise)\n",
        "#     pad_generated_smile = np.array(pad_sequences(generated_smiles, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#     # Select a random batch of real SMILES strings\n",
        "#     idx = np.random.randint(0,real_smile_strings.shape[0] , batch_size)\n",
        "#     real_smiles = real_smile_strings[idx]\n",
        "\n",
        "#     # Labels for real and fake SMILES strings\n",
        "#     valid = np.ones((batch_size, 1))\n",
        "#     fake = np.zeros((batch_size, 1))\n",
        "\n",
        "#     # Train the discriminator (real SMILES strings classified as 1, generated as 0)\n",
        "#     d_loss_real = discriminator.train_on_batch(real_smiles, valid)\n",
        "#     d_loss_fake = discriminator.train_on_batch(pad_generated_smile, fake)\n",
        "#     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "#     # ---------------------\n",
        "#     #  Train Generator\n",
        "#     # ---------------------\n",
        "\n",
        "#     noise = np.random.randint(0, vocab_size, (batch_size, max_sequence_len-1))\n",
        "#     generated_smiles = generator.predict(noise)\n",
        "#     pad_generated_smile = np.array(pad_sequences(generated_smiles, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "#     g_loss = gan.train_on_batch(noise, valid)  # We want the generator to generate valid (real) SMILES strings\n",
        "\n",
        "#     # Print the progress\n",
        "#     # print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] \")\n",
        "#     print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss}]\")\n",
        "\n",
        "# #     # If at save interval -> save generated SMILES string examples\n",
        "# #     if epoch % save_interval == 0:\n",
        "# #         save_generated_smiles(epoch, generator)\n",
        "\n",
        "# # # Function to save generated SMILES strings\n",
        "# # def save_generated_smiles(epoch, generator, examples=10):\n",
        "# #     noise = np.random.randint(0, vocab_size, (examples, maxlen - 1))\n",
        "# #     generated_smiles = generator.predict(noise)\n",
        "\n",
        "# #     for i, smile in enumerate(generated_smiles):\n",
        "# #         smile_str = ''.join([chr(int(t)) for t in smile])  # Convert to readable SMILES (using ASCII as example)\n",
        "# #         print(f\"Generated SMILES string {i}: {smile_str}\")"
      ],
      "metadata": {
        "id": "KMqkk5eu-y7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GENERATE"
      ],
      "metadata": {
        "id": "LNe76llmHu51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "#     for _ in range(next_words):\n",
        "#         token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "#         token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "#         predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\n",
        "#         output_word = \"\"\n",
        "#         for word, index in tokenizer.word_index.items():\n",
        "#             if index == predicted:\n",
        "#                 output_word = word\n",
        "#                 break\n",
        "#         seed_text += \" \" + output_word\n",
        "#     return seed_text\n",
        "\n",
        "# # Esempio di generazione di testo\n",
        "# # seed_text = \"Nostalgia is \"\n",
        "# # next_words = 5\n",
        "# seed_text = \"C\"\n",
        "# next_words = 100\n",
        "# generated_text = generate_text(seed_text, next_words, model, max_sequence_len)\n",
        "# print(\"Testo generato:\", generated_text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gxNYZjfuHpem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\n",
        "        output_char = ''\n",
        "        for char, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_char = char\n",
        "                break\n",
        "        seed_text += output_char\n",
        "    return seed_text\n",
        "\n",
        "# Example of generating a SMILES string\n",
        "# \"CC(C)CC1=CC=    CC=C1\"\n",
        "# \"CC(C)CC1=CC=    CC=C1O\"\n",
        "# CC(C)ccc1=c=cc=c1o\n",
        "\n",
        "seed_text = \"COH\"\n",
        "next_words = 12\n",
        "generated_smiles = generate_text(seed_text, next_words, generator, max_sequence_len)\n",
        "print(\"Generated SMILES:\", generated_smiles)\n"
      ],
      "metadata": {
        "id": "gbb4mSYEMnre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3878bbc4-b7ff-416a-b592-f4b3b0442d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Generated SMILES: COHcc1=c=ccc=c1\n"
          ]
        }
      ]
    }
  ]
}